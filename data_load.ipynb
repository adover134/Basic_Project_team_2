{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d554531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb814d14",
   "metadata": {},
   "source": [
    "각 알약 조합 별, 모든 알약에 대해 정보가 존재하는 이미지들을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d145efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225,\n",
       " 'K-001900-016548-019607-029451_0_2_0_2_70_000_200',\n",
       " 661,\n",
       " 'K-001900-010224-016551-031705_0_2_0_2_70_000_200')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=sorted(os.listdir('./ai06-level1-project/train_images'))\n",
    "annot_root='./ai06-level1-project/train_annotations'\n",
    "annots_t=sorted(os.listdir(annot_root)) # 알약 조합 목록\n",
    "annots_list=[]\n",
    "images_list=[]\n",
    "# 각 알약 조합에 대해\n",
    "for annot_set in annots_t:\n",
    "    # 약 목록을 구한다.\n",
    "    pill_list=sorted(os.listdir(os.path.join(annot_root,annot_set)))\n",
    "    # 첫 약이 가지는 json 파일 목록 (각 이미지에 대한 json 파일 목록)\n",
    "    base_images=sorted(os.listdir(os.path.join(annot_root,annot_set,pill_list[0])))\n",
    "    # 각 약에 대해\n",
    "    for pill in pill_list:\n",
    "        # 각 약이 어떤 이미지에 대한 annotation을 갖는지에 대한 list\n",
    "        imgs=sorted(os.listdir(os.path.join(annot_root,annot_set,pill)))\n",
    "        # 이번 약이 갖지 않는 json 파일들은 제거\n",
    "        base_images=[image for image in base_images if image in imgs]\n",
    "    # 모든 약에 대해, 공통으로 json 파일이 있는 이미지의 이름만 저장\n",
    "    for image in base_images:\n",
    "        annots_list.append(image[:-5])\n",
    "# \n",
    "for img in images:\n",
    "    images_list.append(img[:-4])\n",
    "len(annots_list), annots_list[0], len(images_list),images_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b20972",
   "metadata": {},
   "source": [
    "전체 파일 중, annotation이 이미지의 모든 알약에 대해 있는 이미지들의 이름만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "528f004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_set=set(images_list)\n",
    "annots_set=set(annots_list)\n",
    "# 이미지에 대해, 모든 알약의 annotation이 있는 경우의 이름들을 모음\n",
    "available_files=sorted(list(images_set.intersection(annots_set)))\n",
    "len(available_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a07e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./annots_without_image.txt','w') as f:\n",
    "    for annot in annots_list:\n",
    "        if annot not in images_list:\n",
    "            f.write(str(annot)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f362813",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./images_without_annot.txt','w') as f:\n",
    "    for image in images_list:\n",
    "        if image not in annots_list:\n",
    "            f.write(str(image)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8975f3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-001900-016548-019607-029451_0_2_0_2_70_000_200\n"
     ]
    }
   ],
   "source": [
    "for f in available_files:\n",
    "    print(f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b3422",
   "metadata": {},
   "source": [
    "이미지 단위로 annotation 파일들을 결합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28e0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json 파일 통합\n",
    "\n",
    "base_path = \"./ai06-level1-project\"\n",
    "ann_root = os.path.join(base_path, \"train_annotations\")\n",
    "\n",
    "output_path = os.path.join(base_path, \"train_annots\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "image_id_offset = 0\n",
    "annotation_id_offset = 0\n",
    "category_set = set()\n",
    "\n",
    "# 알약 조합 별 폴더 명\n",
    "for root in sorted(os.listdir(ann_root)):\n",
    "\n",
    "    # 현재 조합의 알약 종류\n",
    "    pills=sorted(os.listdir(os.path.join(ann_root,root)))\n",
    "\n",
    "    # 현재 조합의 이미지 목록\n",
    "    images_list=[]\n",
    "    images = os.listdir(os.path.join(ann_root,root,pills[0]))\n",
    "\n",
    "    if len(images)==0:\n",
    "        continue\n",
    "\n",
    "    # 각 이미지 별 JSON 파일 생성\n",
    "    for img in images:\n",
    "\n",
    "        images=[]\n",
    "        annotations=[]\n",
    "        categories=[]\n",
    "\n",
    "        # 대응하는 이미지가 없거나, 일부 알약에 대해 누락되어 있다 annotation이 누락된 이미지면 continue\n",
    "        if img[:-5] not in available_files:\n",
    "            continue\n",
    "        # 각 알약에 대해서\n",
    "        for pill in pills:\n",
    "            # 해당 이미지의 json 파일을 엽니다.\n",
    "            with open(str(os.path.join(ann_root,root,pill,img)), \"r\", encoding=\"utf-8\") as f:\n",
    "                pill_data = json.load(f)\n",
    "                if len(images)==0:\n",
    "                    images.extend(pill_data[\"images\"])\n",
    "                annotations.extend(pill_data[\"annotations\"])\n",
    "                categories.extend(pill_data[\"categories\"])\n",
    "        output_coco={\n",
    "            \"images\": images,\n",
    "            \"annotations\": annotations,\n",
    "            \"categories\": categories\n",
    "        }\n",
    "        with open(os.path.join(output_path,img), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(output_coco, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce23bbf",
   "metadata": {},
   "source": [
    "이제 모든 이미지의 json 파일을 결합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d3d3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.json 생성됨: ./ai06-level1-project/train.json\n"
     ]
    }
   ],
   "source": [
    "output_all_coco = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "files = os.listdir(os.path.join(base_path, \"train_annots\"))\n",
    "\n",
    "for file in files:\n",
    "    with open(os.path.join(base_path, \"train_annots\", file), \"r\", encoding=\"utf-8\") as f:\n",
    "        data=json.load(f)\n",
    "        for image in data['images']:\n",
    "            output_all_coco['images'].append(image)\n",
    "        for annot in data['annotations']:\n",
    "            output_all_coco['annotations'].append(annot)\n",
    "        for cat in data['categories']:\n",
    "            output_all_coco['categories'].append(cat)\n",
    "            \n",
    "save_path = os.path.join(base_path, \"train.json\")\n",
    "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_all_coco, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"train.json 생성됨:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0820c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "746"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_all_coco['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4b9044cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = r\"./ai06-level1-project\"\n",
    "ANN_FILE = os.path.join(BASE, \"train.json\")\n",
    "with open(ANN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a8401d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "YOLO dataset 생성 완료\n",
      "data.yaml 파일 생성 완료\n"
     ]
    }
   ],
   "source": [
    "#YOLO용으로 데이터 전처리\n",
    "\n",
    "BASE = r\"./ai06-level1-project/\"\n",
    "IMG_DIR = os.path.join(BASE, \"train_output\")\n",
    "ANN_FILE = os.path.join(BASE, \"train.json\")\n",
    "TEST_IMG_DIR = os.path.join(BASE, \"test_images\")\n",
    "\n",
    "OUT_DIR = os.path.join(BASE, \"yolo_dataset\")\n",
    "\n",
    "os.makedirs(os.path.join(OUT_DIR, \"images/train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_DIR, \"images/val\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_DIR, \"labels/train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_DIR, \"labels/val\"), exist_ok=True)\n",
    "\n",
    "with open(ANN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "coco = COCO()\n",
    "coco.dataset = dataset\n",
    "coco.createIndex()\n",
    "\n",
    "img_ids = list(coco.imgs.keys())\n",
    "\n",
    "train_ids, val_ids = train_test_split(img_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def convert_to_yolo_bbox(box, img_w, img_h):\n",
    "    x, y, w, h = box\n",
    "    cx = (x + w/2) / img_w\n",
    "    cy = (y + h/2) / img_h\n",
    "    w /= img_w\n",
    "    h /= img_h\n",
    "    return cx, cy, w, h\n",
    "\n",
    "\n",
    "def process_image(img_id, split=\"train\"):\n",
    "\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    file_name = img_info[\"file_name\"]\n",
    "    width, height = img_info[\"width\"], img_info[\"height\"]\n",
    "\n",
    "    src_img_path = os.path.join(IMG_DIR, file_name)\n",
    "    dst_img_path = os.path.join(OUT_DIR, f\"images/{split}/{file_name}\")\n",
    "\n",
    "    if os.path.exists(src_img_path):\n",
    "        shutil.copy(src_img_path, dst_img_path)\n",
    "    else:\n",
    "        print(\"이미지 없음:\", src_img_path)\n",
    "        return\n",
    "\n",
    "    label_path = os.path.join(OUT_DIR, f\"labels/{split}/{file_name.replace('.png', '.txt')}\")\n",
    "\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "    with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ann in anns:\n",
    "            category_id = ann[\"category_id\"]\n",
    "            yolo_class = list(coco.cats.keys()).index(category_id)\n",
    "            bbox = ann[\"bbox\"]\n",
    "            yolo_box = convert_to_yolo_bbox(bbox, width, height)\n",
    "\n",
    "            f.write(f\"{yolo_class} {' '.join([str(round(v, 6)) for v in yolo_box])}\\n\")\n",
    "\n",
    "\n",
    "for img_id in train_ids:\n",
    "    process_image(img_id, split=\"train\")\n",
    "\n",
    "for img_id in val_ids:\n",
    "    process_image(img_id, split=\"val\")\n",
    "\n",
    "print(\"YOLO dataset 생성 완료\")\n",
    "\n",
    "\n",
    "yaml_path = os.path.join(OUT_DIR, \"data.yaml\")\n",
    "num_classes = len(coco.cats)\n",
    "names = [coco.cats[k][\"name\"] for k in sorted(coco.cats.keys())]\n",
    "\n",
    "with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"path: {OUT_DIR}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\\n\")\n",
    "    f.write(f\"nc: {num_classes}\\n\")\n",
    "    f.write(f\"names: {names}\\n\")\n",
    "\n",
    "print(\"data.yaml 파일 생성 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df22c8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
