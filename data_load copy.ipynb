{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d554531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import shutil\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pycocotools.coco import COCO\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb814d14",
   "metadata": {},
   "source": [
    "각 알약 조합 별, 모든 알약에 대해 정보가 존재하는 이미지들을 구한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7d145efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225,\n",
       " 'K-001900-016548-019607-029451_0_2_0_2_70_000_200',\n",
       " 661,\n",
       " 'K-001900-010224-016551-031705_0_2_0_2_70_000_200')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images=sorted(os.listdir('./ai06-level1-project/train_images'))\n",
    "annot_root='./ai06-level1-project/train_annotations'\n",
    "annots_t=sorted(os.listdir(annot_root)) # 알약 조합 목록\n",
    "annots_list=[]\n",
    "images_list=[]\n",
    "# 각 알약 조합에 대해\n",
    "for annot_set in annots_t:\n",
    "    # 약 목록을 구한다.\n",
    "    pill_list=sorted(os.listdir(os.path.join(annot_root,annot_set)))\n",
    "    # 첫 약이 가지는 json 파일 목록 (각 이미지에 대한 json 파일 목록)\n",
    "    base_images=sorted(os.listdir(os.path.join(annot_root,annot_set,pill_list[0])))\n",
    "    # 각 약에 대해\n",
    "    for pill in pill_list:\n",
    "        # 각 약이 어떤 이미지에 대한 annotation을 갖는지에 대한 list\n",
    "        imgs=sorted(os.listdir(os.path.join(annot_root,annot_set,pill)))\n",
    "        # 이번 약이 갖지 않는 json 파일들은 제거\n",
    "        base_images=[image for image in base_images if image in imgs]\n",
    "    # 모든 약에 대해, 공통으로 json 파일이 있는 이미지의 이름만 저장\n",
    "    for image in base_images:\n",
    "        annots_list.append(image[:-5])\n",
    "# \n",
    "for img in images:\n",
    "    images_list.append(img[:-4])\n",
    "len(annots_list), annots_list[0], len(images_list),images_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b20972",
   "metadata": {},
   "source": [
    "전체 파일 중, annotation이 이미지의 모든 알약에 대해 있는 이미지들의 이름만 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "528f004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "224"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_set=set(images_list)\n",
    "annots_set=set(annots_list)\n",
    "# 이미지에 대해, 모든 알약의 annotation이 있는 경우의 이름들을 모음\n",
    "available_files=sorted(list(images_set.intersection(annots_set)))\n",
    "len(available_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51a07e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./annots_without_image.txt','w') as f:\n",
    "    for annot in annots_list:\n",
    "        if annot not in images_list:\n",
    "            f.write(str(annot)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f362813",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./images_without_annot.txt','w') as f:\n",
    "    for image in images_list:\n",
    "        if image not in annots_list:\n",
    "            f.write(str(image)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8975f3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-001900-016548-019607-029451_0_2_0_2_70_000_200\n"
     ]
    }
   ],
   "source": [
    "for f in available_files:\n",
    "    print(f)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6b3422",
   "metadata": {},
   "source": [
    "이미지 단위로 annotation 파일들을 결합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f28e0a63",
   "metadata": {},
   "outputs": [],
   "source": [
    "#json 파일 통합\n",
    "\n",
    "base_path = \"./ai06-level1-project\"\n",
    "ann_root = os.path.join(base_path, \"train_annotations\")\n",
    "\n",
    "output_path = os.path.join(base_path, \"train_annots\")\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "image_id_offset = 0\n",
    "annotation_id_offset = 0\n",
    "category_set = set()\n",
    "\n",
    "# 알약 조합 별 폴더 명\n",
    "for root in sorted(os.listdir(ann_root)):\n",
    "\n",
    "    # 현재 조합의 알약 종류\n",
    "    pills=sorted(os.listdir(os.path.join(ann_root,root)))\n",
    "\n",
    "    # 현재 조합의 이미지 목록\n",
    "    images_list=[]\n",
    "    images = os.listdir(os.path.join(ann_root,root,pills[0]))\n",
    "\n",
    "    if len(images)==0:\n",
    "        continue\n",
    "\n",
    "    # 각 이미지 별 JSON 파일 생성\n",
    "    for img in images:\n",
    "\n",
    "        images=[]\n",
    "        annotations=[]\n",
    "        categories=[]\n",
    "\n",
    "        # 대응하는 이미지가 없거나, 일부 알약에 대해 누락되어 있다 annotation이 누락된 이미지면 continue\n",
    "        if img[:-5] not in available_files:\n",
    "            continue\n",
    "        # 각 알약에 대해서\n",
    "        for pill in pills:\n",
    "            # 해당 이미지의 json 파일을 엽니다.\n",
    "            with open(str(os.path.join(ann_root,root,pill,img)), \"r\", encoding=\"utf-8\") as f:\n",
    "                pill_data = json.load(f)\n",
    "                if len(images)==0:\n",
    "                    images.extend(pill_data[\"images\"])\n",
    "                annotations.extend(pill_data[\"annotations\"])\n",
    "                categories.extend(pill_data[\"categories\"])\n",
    "        output_coco={\n",
    "            \"images\": images,\n",
    "            \"annotations\": annotations,\n",
    "            \"categories\": categories\n",
    "        }\n",
    "        with open(os.path.join(output_path,img), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(output_coco, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce23bbf",
   "metadata": {},
   "source": [
    "이제 모든 이미지의 json 파일을 결합합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4d3d3bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.json 생성됨: ./ai06-level1-project/train.json\n"
     ]
    }
   ],
   "source": [
    "output_all_coco = {\n",
    "    \"images\": [],\n",
    "    \"annotations\": [],\n",
    "    \"categories\": []\n",
    "}\n",
    "files = os.listdir(os.path.join(base_path, \"train_annots\"))\n",
    "\n",
    "for file in files:\n",
    "    with open(os.path.join(base_path, \"train_annots\", file), \"r\", encoding=\"utf-8\") as f:\n",
    "        data=json.load(f)\n",
    "        for image in data['images']:\n",
    "            output_all_coco['images'].append(image)\n",
    "        for annot in data['annotations']:\n",
    "            output_all_coco['annotations'].append(annot)\n",
    "        for cat in data['categories']:\n",
    "            output_all_coco['categories'].append(cat)\n",
    "\n",
    "t=pd.DataFrame(output_all_coco['categories'])\n",
    "t=t.drop_duplicates()\n",
    "output_all_coco['categories']=t.to_dict(orient='records')\n",
    "\n",
    "save_path = os.path.join(base_path, \"train.json\")\n",
    "with open(save_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(output_all_coco, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(\"train.json 생성됨:\", save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a0820c0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(output_all_coco['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a8401d72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating index...\n",
      "index created!\n",
      "YOLO dataset 생성 완료\n",
      "data.yaml 파일 생성 완료\n"
     ]
    }
   ],
   "source": [
    "#YOLO용으로 데이터 전처리\n",
    "\n",
    "BASE = r\"./ai06-level1-project/\"\n",
    "IMG_DIR = os.path.join(BASE, \"train_output\")\n",
    "ANN_FILE = os.path.join(BASE, \"train.json\")\n",
    "TEST_IMG_DIR = os.path.join(BASE, \"test_images\")\n",
    "\n",
    "OUT_DIR = os.path.join(BASE, \"yolo_dataset\")\n",
    "\n",
    "os.makedirs(os.path.join(OUT_DIR, \"images/train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_DIR, \"images/val\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_DIR, \"labels/train\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_DIR, \"labels/val\"), exist_ok=True)\n",
    "\n",
    "with open(ANN_FILE, \"r\", encoding=\"utf-8\") as f:\n",
    "    dataset = json.load(f)\n",
    "\n",
    "coco = COCO()\n",
    "coco.dataset = dataset\n",
    "coco.createIndex()\n",
    "\n",
    "img_ids = list(coco.imgs.keys())\n",
    "\n",
    "train_ids, val_ids = train_test_split(img_ids, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "def convert_to_yolo_bbox(box, img_w, img_h):\n",
    "    x, y, w, h = box\n",
    "    cx = (x + w/2) / img_w\n",
    "    cy = (y + h/2) / img_h\n",
    "    w /= img_w\n",
    "    h /= img_h\n",
    "    return cx, cy, w, h\n",
    "\n",
    "\n",
    "def process_image(img_id, split=\"train\"):\n",
    "\n",
    "    img_info = coco.loadImgs(img_id)[0]\n",
    "    file_name = img_info[\"file_name\"]\n",
    "    width, height = img_info[\"width\"], img_info[\"height\"]\n",
    "\n",
    "    src_img_path = os.path.join(IMG_DIR, file_name)\n",
    "    dst_img_path = os.path.join(OUT_DIR, f\"images/{split}/{file_name}\")\n",
    "\n",
    "    if os.path.exists(src_img_path):\n",
    "        shutil.copy(src_img_path, dst_img_path)\n",
    "    else:\n",
    "        print(\"이미지 없음:\", src_img_path)\n",
    "        return\n",
    "\n",
    "    label_path = os.path.join(OUT_DIR, f\"labels/{split}/{file_name.replace('.png', '.txt')}\")\n",
    "\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "    with open(label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for ann in anns:\n",
    "            category_id = ann[\"category_id\"]\n",
    "            yolo_class = list(coco.cats.keys()).index(category_id)\n",
    "            bbox = ann[\"bbox\"]\n",
    "            yolo_box = convert_to_yolo_bbox(bbox, width, height)\n",
    "\n",
    "            f.write(f\"{yolo_class} {' '.join([str(round(v, 6)) for v in yolo_box])}\\n\")\n",
    "\n",
    "\n",
    "for img_id in train_ids:\n",
    "    process_image(img_id, split=\"train\")\n",
    "\n",
    "for img_id in val_ids:\n",
    "    process_image(img_id, split=\"val\")\n",
    "\n",
    "print(\"YOLO dataset 생성 완료\")\n",
    "\n",
    "\n",
    "yaml_path = os.path.join(OUT_DIR, \"data.yaml\")\n",
    "num_classes = len(coco.cats)\n",
    "names = [coco.cats[k][\"name\"] for k in sorted(coco.cats.keys())]\n",
    "\n",
    "with open(yaml_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(f\"path: {OUT_DIR}\\n\")\n",
    "    f.write(\"train: images/train\\n\")\n",
    "    f.write(\"val: images/val\\n\\n\")\n",
    "    f.write(f\"nc: {num_classes}\\n\")\n",
    "    f.write(f\"names: {names}\\n\")\n",
    "\n",
    "print(\"data.yaml 파일 생성 완료\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8373adc6",
   "metadata": {},
   "source": [
    "학습을 통해 구분해야 하는 알약 번호 목록을 획득합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "aef5d623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "74"
      ]
     },
     "execution_count": 337,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pill_code=[]\n",
    "images=sorted(os.listdir('./ai06-level1-project/train_images')) # 알약 조합 목록\n",
    "for image in images:\n",
    "    image=list(image[2:-23].split('-'))\n",
    "    pill_code.extend(image)\n",
    "pill_code=sorted(list(set(pill_code)))\n",
    "len(pill_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "91bcf9ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['001900',\n",
       " '002483',\n",
       " '003351',\n",
       " '003483',\n",
       " '003544',\n",
       " '003743',\n",
       " '003832',\n",
       " '004378',\n",
       " '004543',\n",
       " '005094',\n",
       " '005886',\n",
       " '006192',\n",
       " '006563',\n",
       " '010221',\n",
       " '010224',\n",
       " '012081',\n",
       " '012247',\n",
       " '012420',\n",
       " '012778',\n",
       " '013395',\n",
       " '013900',\n",
       " '016232',\n",
       " '016262',\n",
       " '016548',\n",
       " '016551',\n",
       " '016688',\n",
       " '018110',\n",
       " '018147',\n",
       " '018357',\n",
       " '019232',\n",
       " '019552',\n",
       " '019607',\n",
       " '019861',\n",
       " '020014',\n",
       " '020238',\n",
       " '020877',\n",
       " '021026',\n",
       " '021325',\n",
       " '021771',\n",
       " '022074',\n",
       " '022347',\n",
       " '022362',\n",
       " '022627',\n",
       " '023203',\n",
       " '023223',\n",
       " '024850',\n",
       " '025367',\n",
       " '025438',\n",
       " '025469',\n",
       " '027653',\n",
       " '027733',\n",
       " '027777',\n",
       " '027926',\n",
       " '027993',\n",
       " '028763',\n",
       " '029345',\n",
       " '029451',\n",
       " '029667',\n",
       " '029871',\n",
       " '030308',\n",
       " '031705',\n",
       " '031863',\n",
       " '031885',\n",
       " '032310',\n",
       " '033009',\n",
       " '033208',\n",
       " '033878',\n",
       " '033880',\n",
       " '034597',\n",
       " '035206',\n",
       " '036637',\n",
       " '038162',\n",
       " '041768',\n",
       " '044199']"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pill_code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8671a041",
   "metadata": {},
   "source": [
    "다운받은 annotation 데이터에 대해, 기존 train dataset에 있는 알약을 하나도 포함하지 않는 경우 전부 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "2cfe3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p='../166.약품식별_인공지능_개발을_위한_경구약제_이미지_데이터/01.데이터/1.Training/라벨링데이터'\n",
    "pills_datasets=sorted(os.listdir(d_p))\n",
    "not_in=[]\n",
    "\n",
    "for pills_dataset in pills_datasets:\n",
    "    for set_name in sorted(os.listdir(os.path.join(d_p,pills_dataset))):\n",
    "        pill_ids_set=list(set_name[2:-5].split('-'))\n",
    "        if any([id in pill_code for id in pill_ids_set]):\n",
    "            continue\n",
    "        not_in.append(os.path.join(d_p,pills_dataset,set_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "id": "c457930b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in not_in:\n",
    "    os.system(f'rm -rf {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569e1e3",
   "metadata": {},
   "source": [
    "살아남은 annotation 파일들을 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "id": "c6ea885f",
   "metadata": {},
   "outputs": [],
   "source": [
    "annotations=[]\n",
    "pills_datasets=sorted(os.listdir(d_p))\n",
    "# 각 라벨링데이터 폴더 내부에서\n",
    "for pills_dataset in pills_datasets:\n",
    "    # 각 조합 폴더 내에서\n",
    "    for set_name in sorted(os.listdir(os.path.join(d_p,pills_dataset))):\n",
    "        # 조합을 저장한다.\n",
    "        annotations.append(set_name[:-5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "b101dc61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2752"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(annotations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beccd4df",
   "metadata": {},
   "source": [
    "이미지 중, index를 이름에 포함하는 것은 삭제하고, 대응하는 annotation이 없는 이미지도 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "f30b77d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p='../166.약품식별_인공지능_개발을_위한_경구약제_이미지_데이터/01.데이터/1.Training/원천데이터'\n",
    "pills_image_datasets=sorted(os.listdir(d_p))\n",
    "not_in=[]\n",
    "\n",
    "for pills_dataset in pills_image_datasets:\n",
    "    for set_name in sorted(os.listdir(os.path.join(d_p,pills_dataset))):\n",
    "        if set_name not in annotations:\n",
    "            not_in.append(os.path.join(d_p,pills_dataset,set_name))\n",
    "        files=sorted(os.listdir(os.path.join(d_p,pills_dataset,set_name)))\n",
    "        if len(files)==0:\n",
    "            os.system(f'rm -rf {os.path.join(d_p,pills_dataset,set_name)}')\n",
    "            continue\n",
    "        for file in files:\n",
    "            if 'index' in file:\n",
    "                os.system(f'rm {os.path.join(d_p,pills_dataset,set_name,file)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "ad750fc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "751"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(not_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "96e99ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in not_in:\n",
    "    os.system(f'rm -rf {n}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a9943",
   "metadata": {},
   "source": [
    "살아남은 이미지 목록을 구합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "5ac90ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p='../166.약품식별_인공지능_개발을_위한_경구약제_이미지_데이터/01.데이터/1.Training/원천데이터'\n",
    "pills_datasets=sorted(os.listdir(d_p))\n",
    "images=[]\n",
    "\n",
    "for pills_dataset in pills_datasets:\n",
    "    for set_name in sorted(os.listdir(os.path.join(d_p,pills_dataset))):\n",
    "        image_names=os.listdir(os.path.join(d_p,pills_dataset,set_name))\n",
    "        for image_name in image_names:\n",
    "            images.append(image_name[:-4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "85d02a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8234"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d88d99",
   "metadata": {},
   "source": [
    "대응하는 이미지 파일이 없는 annotation들을 삭제합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c485c546",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p='../166.약품식별_인공지능_개발을_위한_경구약제_이미지_데이터/01.데이터/1.Training/라벨링데이터'\n",
    "pills_datasets=sorted(os.listdir(d_p))\n",
    "# 각 폴더마다\n",
    "for pills_dataset in pills_datasets:\n",
    "    # 각 약 조합마다\n",
    "    for set_name in sorted(os.listdir(os.path.join(d_p,pills_dataset))):\n",
    "        # 각 약 폴더마다\n",
    "        for pill in sorted(os.listdir(os.path.join(d_p,pills_dataset,set_name))):\n",
    "            # 디렉토리가 아닌 것은 삭제\n",
    "            if not os.path.isdir(os.path.join(d_p,pills_dataset,set_name,pill)):\n",
    "                os.system(f'rm \"{os.path.join(d_p,pills_dataset,set_name,pill)}\"')\n",
    "                continue\n",
    "            # 하위의 json 파일 중 대응하는 이미지가 없다면 삭제\n",
    "            annots=sorted(os.listdir(os.path.join(d_p,pills_dataset,set_name,pill)))\n",
    "            for annot in annots:\n",
    "                if annot[:-5] in images:\n",
    "                    continue\n",
    "                else:\n",
    "                    os.system(f'rm \"{os.path.join(d_p,pills_dataset,set_name,pill,annot)}\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffd3b275",
   "metadata": {},
   "source": [
    "train_image 폴더에 넣었었는데, 그 내부의 각 폴더의 이미지들을 다 train_images라는 하나의 폴더로 옮기겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "6fc280ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "d_p='../166.약품식별_인공지능_개발을_위한_경구약제_이미지_데이터/01.데이터/1.Training/원천데이터'\n",
    "from_p=d_p+'/train_image'\n",
    "to_p=d_p+'/train_images'\n",
    "pills_datasets=sorted(os.listdir(from_p))\n",
    "images=[]\n",
    "\n",
    "# 각 이미지 폴더마다\n",
    "for pills_dataset in pills_datasets:\n",
    "    # 내부의 이미지들을 구하고\n",
    "    image_list=sorted(os.listdir(os.path.join(from_p,pills_dataset)))\n",
    "    # 각 이미지를 to_p로 옮긴다.\n",
    "    for image in image_list:\n",
    "        os.system(f'mv {os.path.join(from_p,pills_dataset,image)} \"{os.path.join(to_p,image)}\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd400cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "codeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
